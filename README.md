# ğŸ§  Tokenizer Visualizer

An interactive Streamlit app to explore how different language models tokenize text. This project allows users to input any sentence and visualize how popular LLMs like GPT-2, BERT, and T5 break down the input into tokens, token IDs, and attention masks.

## ğŸš€ Features
- Input any text and choose one or more tokenizers
- Supports GPT-2 (BPE), BERT (WordPiece), and T5 (SentencePiece)
- Shows:
  - Tokens
  - Token IDs
  - Attention Mask
  - Token count

## ğŸ”§ Technologies Used
- Python
- Streamlit
- Hugging Face Transformers

## ğŸ“¦ Installation
```bash
git clone https://github.com/yourusername/tokenizer-visualizer.git
cd tokenizer-visualizer
pip install -r requirements.txt
```

## â–¶ï¸ Running the App
```bash
streamlit run app.py
```

## ğŸ§ª Example Prompt
Input: `"The future of AI is incredibly exciting!"`

Youâ€™ll see how:
- GPT-2 splits words with space-tokens (e.g., `Ä future`)
- BERT splits rare words into subwords (e.g., `un##believable`)
- T5 uses underscore-based pieces (e.g., `â–The`, `â–future`)

## ğŸ“ Learning Outcomes
- Understand how different tokenizers interpret input
- Explore token fragmentation and input efficiency
- Visualize model preprocessing steps

## ğŸ“¬ Contact
Feel free to connect on [LinkedIn](https://www.linkedin.com/in/arvindcharypadala/) or [GitHub](https://github.com/arvindchary)

---
Made with â¤ï¸ for the love of LLMs & learning!
